
def train(Generator,Discriminator,batch_size,n_epochs,dataset,lr_g,lr_d,processing_unit):

    """
    ----- INPUT -----
    Generator -> class of the generator
    Discriminator -> class of the discriminator
    batch_size,n_epochs,lr -> number
    dataset -> -> object dataset  

    ----- OUTPUT -----
    metrics to measure the accuracy of the models 

    """

    gen_net = Generator
    dis_net = Discriminator
    best_epoch_G = -1
    best_epoch_D = -1

    dataset.preprocessing() 
    

    
    optimizer_gen = torch.optim.Adam([p for p in gen_net.parameters() if p.requires_grad], lr_g, maximize=True) #torch.optim.Adam(filter(lambda p: p.requires_grad, self.net.parameters()), lr)
    optimizer_dis = torch.optim.Adam([p for p in dis_net.parameters() if p.requires_grad], lr_d, maximize=False)

    best_loss_D = 1000000000000 
    best_loss_G = 1000000000000

    gen_net.net.train()
    dis_net.net.train()

    for e in range(0,n_epochs):


        last_batch = False

        image_file, _ = dataset.shuffled_dataset()
        length_dataset = len(image_file)

        counter_batches = 0
        tot_loss_D = 0
        tot_loss_G = 0
        avg_loss_D = 0
        avg_loss_G = 0

        while not last_batch:

            counter_batches = counter_batches + 1

            #fake batch creation
            x_gen_input, _ = gen_net.input_creation(length_dataset = length_dataset , batch_size = batch_size)
            current_batch_dim = x_gen_input.shape

            with torch.no_grad():
                #move the data into the processing unit device
                x_gen_input = x_gen_input.to(processing_unit)
                #fake image generated by Generator
                image_output_fake,label_fake_img = gen_net.forward_G(x_gen_input)

            #true image generation
            mini_batch_image_real, mini_batch_label_real, last_batch_flag = dataset.mini_batch_creation(batch_size,image_file)

            #combination real/fake image into the cpu
            image_output_fake = image_output_fake.to('cpu')
            label_fake_img = label_fake_img.to('cpu')
            mini_batch_img_comb, mini_batch_lab_comb  = dis_net.combined_True_Fake(
                fake_labels = label_fake_img, fake_images = image_output_fake, 
                true_labels = mini_batch_label_real , true_images = mini_batch_image_real
            )

            #relocate the combined images into the processing unit 
            mini_batch_img_comb = mini_batch_img_comb.to(processing_unit)
            predicted_label = dis_net.forward_D(mini_batch_img_comb)

            #------------
            # BackProp Discriminator 
            #------------
            
            #move to processing unit 
            predicted_label = predicted_label.to(processing_unit)
            mini_batch_lab_comb = mini_batch_lab_comb.to(processing_unit)

            loss_dis = dis_net.function_loss_D(output_label_dis = predicted_label,true_label = mini_batch_lab_comb)
            tot_loss_D = tot_loss_D + loss_dis

            optimizer_dis.zero_grad()
            loss_dis.backward()
            optimizer_dis.step()


            #----------
            #BackProp Generator
            #----------

            x_gen_input,_ = gen_net.input_creation(length_dataset = length_dataset , batch_size = batch_size, current_batch_dim = current_batch_dim)
            x_gen_input = x_gen_input.to(processing_unit)

            x_gen_input,_ = gen_net.input_creation(length_dataset = length_dataset , batch_size = batch_size, current_batch_dim = current_batch_dim)
            image_output_fake,fake_target = gen_net.forward_G(x_gen_input)
            predicted_label_generated = dis_net.forward_D(image_output_fake)
            fake_target = fake_target.view(-1,1)

            #move to processing unit
            predicted_label_generated = predicted_label_generated.to(processing_unit)
            fake_target = fake_target.to(processing_unit)

            loss_gen = gen_net.function_loss_G(output_label_gen = predicted_label_generated, true_label = fake_target)

            tot_loss_G = tot_loss_G + loss_gen 

            optimizer_gen.zero_grad()
            loss_gen.backward()
            optimizer_gen.step()
            

            last_batch = last_batch_flag


        #gen_net.image_generation()

        avg_loss_G = tot_loss_G/counter_batches
        avg_loss_D = tot_loss_D/counter_batches

        if avg_loss_D < best_loss_D:
            best_loss_D = avg_loss_D
            best_epoch_D = e + 1
            dis_net.save("weights_discriminator.pth")
            
        if avg_loss_G < best_loss_G:
          best_loss_G = avg_loss_G
          best_epoch_G = e + 1
          gen_net.save("weights_generator.pth")

       
        print("epoch:{0}/{1}".format(e+1,n_epochs)) 
              
        print(("DISCRIMIATOR: BCE LOSS={0:.4f}"
                   + (", BEST!" if avg_loss_D == best_loss_D else ""))
                  .format(avg_loss_D))
            
        print(("GENERATOR: BCE LOSS={0:.4f}"
                   + (", BEST!" if avg_loss_G == best_loss_G else ""))
                  .format(avg_loss_G))
            
        print("========================================================================================= \n")



            





def separation(predicted_label):

    """
    divide the true from the generated data in orded to do backprop in the generator 
    """

    length = int(predicted_label.shape[0]/2)

    fake_label = predicted_label[length:]
    fake_label = fake_label.view(1,-1)

    return fake_label
    

def parse_command_line_arguments():
    """Parse command line arguments, checking their values."""

    parser = argparse.ArgumentParser(description='')
    parser.add_argument('device', type = str, choices=['colab', 'local'],
                        help='where the scripts will run')
    parser.add_argument('lr_g', type=float, default=0.001,
                        help='learning rate (Adam) (default: 0.001) for GENERATOR')
    parser.add_argument('lr_d', type=float, default=0.001,
                        help='learning rate (Adam) (default: 0.001) for DISCRIMINATOR')
    parser.add_argument('path_source', type=str, default = "/Users/tommasoancilli/Downloads/img_celeba_dataset.zip",
                        help='where the downloaded dataset is stored: mine was in /Users/tommasoancilli/Downloads/img_celeba_dataset.zip')
    parser.add_argument('path_destination', type=str, default = "/Users/tommasoancilli/Desktop/Python/NN_proj/img_celeba_dataset",
                        help='where you want to store the unzipped dataset: mine was in /Users/tommasoancilli/Desktop/Python/NN_proj/img_celeba_dataset')
    parser.add_argument('p_subset', type=float, default='0.25',
                        help='fraction of data kept for generating the images')
    parser.add_argument('batch_size', type=int, default=100,
                        help='mini-batch size (default: 100)')
    parser.add_argument('epochs', type=int, default=15,
                        help='number of training epochs (default: 15)')
    #parser.add_argument('--backbone', type=str, default='resnet', choices=['resnet', 'simplecnn'],
                       # help='backbone network for feature extraction (default: resnet)"')

    parsed_arguments = parser.parse_args()

    return parsed_arguments
