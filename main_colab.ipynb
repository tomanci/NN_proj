{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8kcBpsXh9ikN"
      },
      "outputs": [],
      "source": [
        "#package required\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import shutil \n",
        "import PIL\n",
        "import os \n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from torchvision import transforms \n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBv2cPtN-Gr6"
      },
      "source": [
        "# class dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-UJZNGmK9rU5"
      },
      "outputs": [],
      "source": [
        "class Dataset():\n",
        "    \"\"\"\n",
        "    We transfer the kaggle dataset into a folder where the python environment is. \n",
        "    path_source is where the kaggle dataset downloaded is, path destination is where it should be placed the unzipped dataset.[by default there are my paths] \n",
        "    \"\"\"\n",
        "    def __init__(self,path_destination):\n",
        "\n",
        "        self.path_destination = path_destination\n",
        "        self.file_id = 0\n",
        "        self.files = []\n",
        "        self.true_labels = []\n",
        "        \n",
        "\n",
        "        !pip install unzip\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/gdrive')\n",
        "        !cp /content/gdrive/MyDrive/NN_dataset/img_celeba_dataset.zip /content\n",
        "        !unzip \"/content/img_celeba_dataset.zip\" -d \"/content\"\n",
        "               \n",
        "        \n",
        "    def preprocessing(self,p_subset=0.25):\n",
        "        \n",
        "        \"\"\"\n",
        "        preprocessing function creates the dataset folder where a subset of the original images is taken \n",
        "        --- INPUT ---\n",
        "        p_subset = the percentage of the image transfered to the dataset default = 0.25\n",
        "\n",
        "        --- OUTPUT ---\n",
        "        dataset folder with the preprocessed images. \n",
        "        Each image has undergone to the following processes\n",
        "        1) crop it and centralized \n",
        "        2) downsampled to 64x64 resolution\n",
        "        3) converted from a RGB to a grayscale image [computational reason]\n",
        "        \"\"\"\n",
        "\n",
        "        self.p_subset = p_subset\n",
        "\n",
        "        #creation of the path where the new dataset will be stored\n",
        "        self.path_dataset = os.path.join(os.getcwd(),\"dataset\")\n",
        "        os.mkdir(self.path_dataset)\n",
        "\n",
        "        self.counter_photos = 0\n",
        "        self.counter_dataset = 0\n",
        "\n",
        "        for photo in os.listdir(self.path_destination):\n",
        "\n",
        "            self.counter_photos = self.counter_photos +1\n",
        "            if torch.rand(1) <= p_subset:\n",
        "\n",
        "                self.counter_dataset = self.counter_dataset +1\n",
        "                #directory of each photo example (../img_celeba_dataset/19736.jpeg)\n",
        "                dir = os.path.join(self.path_destination,photo)\n",
        "\n",
        "                #in sequence, I open the photo, crop it, resize(downsampled to a 64x64 resolution) and convert into a greyscale  \n",
        "                im = Image.open(dir).crop((20,45,150,185)).resize((64,64))#.convert(\"L\")#140x140 before resize #crop((30,55,150,175))#120x120\n",
        "                #save the new image into that directory\n",
        "                im.save(str(self.path_dataset+\"/\"+\"real_\"+photo))\n",
        "\n",
        "        print(\"counter photos {} counter dataset {} ratio {}\".format(self.counter_photos,self.counter_dataset, self.counter_dataset/self.counter_photos))\n",
        "\n",
        "    \n",
        "    def shuffled_dataset(self,boolean_shuffle=True):\n",
        "\n",
        "        \"\"\"\n",
        "        mixed the dataset, by returning a list containing the path of every single image, which will be needed when we have to upload the mini batch\n",
        "        a stupid example of an entries of self.files is like: \"/Users/tommasoancilli/Desktop/Python/NN_proj/dataset/real_8328239.jpg\"\n",
        "        \"\"\"\n",
        "        self.path_dataset = os.path.join(os.getcwd(),\"dataset/\")\n",
        "\n",
        "        self.files = [os.path.join(self.path_dataset,f) for f in os.listdir(self.path_dataset)]\n",
        "        self.true_labels = [1]*len(self.files)\n",
        "\n",
        "        if boolean_shuffle:\n",
        "            shuffled_list = torch.randperm(len(self.files))\n",
        "\n",
        "            self.files = [self.files[i] for i in shuffled_list]\n",
        "            self.true_labels = [self.true_labels[i] for i in shuffled_list]\n",
        "\n",
        "        return self.files, self.true_labels\n",
        "\n",
        "\n",
        "    def load_and_conversion(self,file_img):\n",
        "\n",
        "        \"\"\"\n",
        "        ----- INPUT -----\n",
        "\n",
        "        ----- OUTPUT -----\n",
        "\n",
        "        img_tensor : tensor of the image, being converted from a .jpg format to a tensor one\n",
        "        label_tensor : tensor of the label \n",
        "        end_dataset : flag showing the bottom of the dataset \n",
        "        \"\"\"\n",
        "        files = file_img\n",
        "        self.end_dataset = False\n",
        "\n",
        "        im = Image.open(self.files[self.file_id])\n",
        "        label = self.true_labels[self.file_id]\n",
        "         \n",
        "        convert_tensor = transforms.ToTensor()\n",
        "\n",
        "        img_tensor = convert_tensor(im)\n",
        "        label_tensor = torch.tensor(label)\n",
        "\n",
        "        if self.file_id < len(self.files)-1:\n",
        "            self.file_id = self.file_id +1\n",
        "        else:\n",
        "            self.end_dataset = True\n",
        "            self.file_id = 0 #reset the index\n",
        "\n",
        "\n",
        "        return img_tensor,label_tensor,self.end_dataset\n",
        "\n",
        "\n",
        "\n",
        "    def mini_batch_creation(self, batch_size,file_img):\n",
        "        \"\"\"\n",
        "        ------ INPUT ------\n",
        "        batch_size: given by the users \n",
        "\n",
        "        ----- OUTPUT -----\n",
        "        mini_batch_image: batch of images, its shape is a 4D tensor #batch_size x #channels x width x height\n",
        "        mini_batch_labels: batch of labels, its a tensor: 1 x #batch_size \n",
        "        last_batch_flag: flag variable to say when we have reached the last batch. In this way, in the training function it will indicate the end of a epoch \n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        i = 0\n",
        "        self.data_batch_im = []\n",
        "        self.data_batch_label = []\n",
        "\n",
        "        last_batch_flag = False\n",
        "\n",
        "        while i < batch_size:\n",
        "            \n",
        "            img,label,end_dataset_flag = self.load_and_conversion(file_img)\n",
        "\n",
        "            self.data_batch_im.append(img)\n",
        "            self.data_batch_label.append(label)\n",
        "            last_batch = end_dataset_flag\n",
        "\n",
        "            i = i + 1\n",
        "\n",
        "            if last_batch:\n",
        "                last_batch_flag = True\n",
        "                break\n",
        "        \n",
        "        mini_batch_image = torch.stack(self.data_batch_im,dim=0)\n",
        "        mini_batch_label = torch.stack(self.data_batch_label,dim=0).view(1,-1)\n",
        "\n",
        "        return mini_batch_image, mini_batch_label, last_batch_flag\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HWR8ZEEB-yHw"
      },
      "source": [
        "# ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R2Go0_8Z-2Zx"
      },
      "outputs": [],
      "source": [
        "class Generator(): #puÃ² sia essere il Generator nelle GAN che una classica NN negli adversarial attack\n",
        "\n",
        "    \"\"\"\n",
        "    input: tensor (5,5,5) x,y,z dimension\n",
        "\n",
        "    output: tenror (64,64,3) xyz\n",
        "\n",
        "    Inner structure: an autoencoder where the third layer is the deepest \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,processing_unit,structure):\n",
        "        \n",
        "        if structure == \"CNN\":\n",
        "          self.layers = []\n",
        "\n",
        "          self.layers.append(nn.Conv2d(3, 64, kernel_size=3, padding=1)) #stride = 1 default\n",
        "          self.layers.append(nn.LeakyReLU(negative_slope=0.01, inplace=True))#layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "          self.layers.append(nn.Conv2d(64, 128, kernel_size=5,padding=2)) #stride = 1 default\n",
        "          self.layers.append(nn.LeakyReLU(negative_slope=0.01, inplace=True))\n",
        "\n",
        "          #depthwise separable CNN layer\n",
        "          #self.layers.append(nn.Conv2d(128,128,kernel_size=7,padding=3,groups=128))\n",
        "          #self.layers.append(nn.Conv2d(128,256,kernel_size=1))\n",
        "          self.layers.append(nn.Conv2d(128, 256, kernel_size=7, padding=3)) #stride = 1 default\n",
        "          self.layers.append(nn.LeakyReLU(negative_slope=0.01, inplace=True))\n",
        "\n",
        "          self.layers.append(nn.Conv2d(256, 64, kernel_size=3, padding=1)) #stride = 1 default\n",
        "          self.layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "          self.layers.append(nn.Conv2d(64, 3, kernel_size=3, padding=1)) #stride = 1 default\n",
        "          self.layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "          self.net = nn.Sequential(*self.layers)\n",
        "\n",
        "          self.input_shape = (3,64,64)\n",
        "\n",
        "        \n",
        "        elif structure == \"conventional\":\n",
        "        \n",
        "          self.layers = []\n",
        "\n",
        "          self.layers.append(nn.ConvTranspose2d(in_channels=5,out_channels=128,kernel_size=4,padding=2,stride=1))#[5,5,5] -> [4,4,128]\n",
        "          self.layers.append(nn.ReLU())\n",
        "          self.layers.append(nn.BatchNorm2d(128))\n",
        "\n",
        "          self.layers.append(nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=3,padding=2,stride=3))#[4,4,128] -> [8,8,64]\n",
        "          self.layers.append(nn.ReLU())\n",
        "          self.layers.append(nn.BatchNorm2d(64))\n",
        "\n",
        "          self.layers.append(nn.ConvTranspose2d(in_channels=64,out_channels=32,kernel_size=4,padding=1,stride=2))#[8,8,64] -> [16,16,32]\n",
        "          self.layers.append(nn.ReLU())\n",
        "          self.layers.append(nn.BatchNorm2d(32))\n",
        "\n",
        "          self.layers.append(nn.ConvTranspose2d(in_channels=32,out_channels=16,kernel_size=4,padding=1,stride=2))#[16,16,32] -> [32,32,16]\n",
        "          self.layers.append(nn.ReLU())\n",
        "\n",
        "          self.layers.append(nn.ConvTranspose2d(in_channels=16,out_channels=3,kernel_size=2,padding=0,stride=2))#[32,32,16] -> [64,64,3]\n",
        "          self.layers.append(nn.ReLU())\n",
        "\n",
        "          self.net = nn.Sequential(*self.layers)\n",
        "\n",
        "          self.input_shape = (5,5,5)\n",
        "\n",
        "        \n",
        "\n",
        "        self.device = torch.device(processing_unit)\n",
        "        self.net = self.net.to(self.device)\n",
        "        self.position = 0\n",
        "\n",
        "\n",
        "    \n",
        "    def forward_G(self, x_input):\n",
        "\n",
        "      \"\"\"\n",
        "      ----- Input -----\n",
        "      x_input -> tensor, dimension #example_mini_batch x #channels x width x height \n",
        "\n",
        "      ----- Output ----\n",
        "      self.image_output -> tensor, dimension #example_mini_batch #channels x width x height \n",
        "      self.label_fake_img -> tensor, dimension 1 x #example_mini_batch\n",
        "\n",
        "      \"\"\"\n",
        "\n",
        "      self.image_output = self.net(x_input)\n",
        "      self.label_fake_img = torch.tensor([[0]*len(x_input)])\n",
        "\n",
        "      return self.image_output,self.label_fake_img\n",
        "\n",
        "\n",
        "    def function_loss_G(self,output_label_gen,true_label):\n",
        "      \"\"\"\n",
        "      ----- INPUT -----\n",
        "      output_label_gen -> tensor 1 x #batch_sample\n",
        "      true_label -> tensor 1 x #batch_sample\n",
        "      ----- OUTPUT -----\n",
        "\n",
        "      loss function. \n",
        "      (it is negative because we want to maximize and generally backprop follows the discent of the gradient, so the max = - min )\n",
        "      \"\"\"\n",
        "      cost_function = nn.BCELoss()\n",
        "      true_label = true_label.to(torch.float) #aggiunto questo \n",
        "      loss = cost_function(output_label_gen,true_label)#-cost_function(output_label_gen,true_label)\n",
        "\n",
        "      return loss\n",
        "\n",
        "\n",
        "    def image_generation(self):\n",
        "      \"\"\"\n",
        "      This function will be used to display a image or more after ending each batch/epoch...\n",
        "      \"\"\"\n",
        "\n",
        "      random_input = torch.rand((1,self.input_shape))\n",
        "      #random_input = torch.rand((3,64,64))\n",
        "      random_input = random_input.to(self.device)\n",
        "      transform = T.ToPILImage()#function to transform a tensor into a image\n",
        "      out = self.net(random_input)\n",
        "      out = out.view(out.shape[0]*out.shape[1],out.shape[2],out.shape[3])\n",
        "      im = transform(out)\n",
        "\n",
        "      return im#im.show()\n",
        "      \n",
        "    def creation_image(self, length_dataset):\n",
        "\n",
        "      \"\"\"\n",
        "        ----- INPUT -----\n",
        "        length_dataset -> int value\n",
        "\n",
        "        ----- OUTPUT ------\n",
        "        a tensor image (img) and a boolean function if the we have reached the end of the dataset\n",
        "      \"\"\"\n",
        "\n",
        "      img = torch.rand(self.input_shape)\n",
        "\n",
        "      end_dataset = False\n",
        "      \n",
        "      if self.position <  length_dataset -1:\n",
        "        self.position = self.position +1 \n",
        "      else:\n",
        "        self.position = 0\n",
        "        end_dataset = True\n",
        "\n",
        "      return img, end_dataset\n",
        "    \n",
        "    def input_creation(self,length_dataset,batch_size,current_batch_dim = None):\n",
        "      \"\"\"\n",
        "      ----- INPUT -----\n",
        "      length_dataset -> int value \n",
        "      batch_size -> int value\n",
        "\n",
        "      ----- OUTPUT -----\n",
        "      batch_input, 4D tensor: #sample_batch x #channels x width x height  \n",
        "      \"\"\"\n",
        "      if current_batch_dim == None:\n",
        "\n",
        "        length_dataset = length_dataset\n",
        "        i = 0\n",
        "        self.batch_input = []\n",
        "\n",
        "        last_batch = False\n",
        "\n",
        "        while i < batch_size:\n",
        "\n",
        "          img,end_dataset_flag = self.creation_image(length_dataset)\n",
        "          self.batch_input.append(img)\n",
        "          last_batch = end_dataset_flag\n",
        "\n",
        "          i = i + 1\n",
        "        \n",
        "          if last_batch:\n",
        "            break\n",
        "\n",
        "        self.batch_input = torch.stack(self.batch_input,dim = 0)\n",
        "\n",
        "      else:\n",
        "        \n",
        "        last_batch = False\n",
        "        \n",
        "        self.batch_input = torch.rand((current_batch_dim))\n",
        "\n",
        "\n",
        "\n",
        "      #print(\"type value BEFORE GOING TO THE MAIN\",type(self.batch_input),self.batch_input.size)\n",
        "      return self.batch_input, last_batch\n",
        "\n",
        "\n",
        "    def summary(self):\n",
        "    #per vedere i parametrei for l in self.layers : l.size()\n",
        "      total_param = 0\n",
        "      param_string = \"\"\n",
        "\n",
        "      for l in self.layers:\n",
        "        parameters = 0\n",
        "\n",
        "        if \"Conv\" in str(l):\n",
        "          param_string = param_string + \"======================================================\" + \"\\n\"\n",
        "          param_string = param_string + str(l) + \"\\n\"\n",
        "          param_string = l.in_channels * l.kernel_size[0]*l.kernel_size[1]*l.out_channels + l.out_channels\n",
        "          param_string = param_string + \"Number of parameters for this layer: {}\".format(parameters) + \"\\n\"\n",
        "\n",
        "          total_param = total_param + parameters\n",
        "        \n",
        "        else:\n",
        "          param_string = param_string + \"======================================================\" + \"\\n\"\n",
        "          param_string = param_string + str(l) + \"\\n\"\n",
        "          param_string = param_string + \"Number of parameters for this layer:{} \".format(parameters)+\"\\n\"\n",
        "\n",
        "      param_string = param_string + \"----------------------------------------------------\" + \"\\n\"  \n",
        "      param_string = param_string + \"Total number of learnable parameters: {}\".format(total_param)\n",
        "\n",
        "    \n",
        "      print(param_string)\n",
        "    \n",
        "    def save(self,file_name):\n",
        "      torch.save(self.net.state_dict(), file_name)\n",
        "\n",
        "\n",
        "\n",
        "class Discriminator():\n",
        "\n",
        "    def __init__(self,processing_unit):\n",
        "        self.layers = []\n",
        "\n",
        "        self.layers.append(nn.Conv2d(3,32,kernel_size=7,padding = \"same\"))#64x64x32\n",
        "        self.layers.append(nn.AvgPool2d(2,stride=2))#32x32x32\n",
        "        self.layers.append(nn.LeakyReLU(inplace=True))\n",
        "\n",
        "        self.layers.append(nn.Conv2d(32,64,kernel_size=5,padding=\"same\"))#32x32x64\n",
        "        self.layers.append(nn.AvgPool2d(2,stride=2))#16x16x64\n",
        "        self.layers.append(nn.LeakyReLU(inplace=True))\n",
        "\n",
        "        self.layers.append(nn.Conv2d(64,128,kernel_size=3,padding=1,stride=2))#8x8x128\n",
        "        self.layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "        self.layers.append(nn.Conv2d(128,256,kernel_size=3,padding=1,stride=2))#4x4x256\n",
        "        self.layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "        self.layers.append(nn.Flatten())#256X16\n",
        "\n",
        "        self.layers.append(nn.Linear(in_features=256*4*4,out_features=1))\n",
        "\n",
        "        self.layers.append(nn.Sigmoid())\n",
        "\n",
        "        self.net = nn.Sequential(*self.layers)\n",
        "\n",
        "        self.device = torch.device(processing_unit)\n",
        "        self.net = self.net.to(self.device)\n",
        "\n",
        "    \n",
        "    def combined_True_Fake(self, fake_labels, fake_images, true_labels, true_images):\n",
        "      \"\"\"\n",
        "        ----- Input ----\n",
        "        fake_labels, fake_images, true_labels, true_images -> tensor\n",
        "        dimensions:\n",
        "        fake_images, true images = #of_example_mini_batch x #channles x width x height\n",
        "        fake/true labels = 1x#of_example_mini_batch\n",
        "\n",
        "        ----- Output ------\n",
        "        combined_images, combined_label -> tensor\n",
        "        dimension:\n",
        "        combined_label = 1 x #examples_mini_batch\n",
        "        combined_images = 2*#examples_mini_batch x width x height \n",
        "\n",
        "      \"\"\"\n",
        "\n",
        "#      if len(fake_labels) != len(true_labels) and fake_images.shape != true_images.shape:\n",
        "#        raise ValueError(\"THE DIMENSIONS ARE NOT THE SAME!\")\n",
        "\n",
        "      combined_images = torch.stack([true_images,fake_images],dim=0)\n",
        "      # combined_images dimension = 2(number of tensor combined into a list) x #mini_batches x channels x width x height\n",
        "      combined_images = combined_images.view(\n",
        "        combined_images.shape[0]*combined_images.shape[1],\n",
        "        combined_images.shape[2],combined_images.shape[3],combined_images.shape[4]\n",
        "      )\n",
        "      #with view I reshape the dimension, compressing the first two dimention into a single one.\n",
        "      #it's like pilling up the tensor one after the other in the dimension of the mini batches \n",
        "\n",
        "      #hstack -> it stacks the tensor horizionally, so from two tensor of shape [1,n] and [1,n] it prints out [1,2*n]\n",
        "      combined_labels = torch.hstack([true_labels,fake_labels])\n",
        "      combined_labels = combined_labels.view(-1,1)\n",
        "      #view(-1,1) it's like numpy.reshape and it \"transpose\" creating a [2*n,1] vector \n",
        "\n",
        "      return combined_images,combined_labels\n",
        "\n",
        "    def forward_D(self,images):\n",
        "      \"\"\"\n",
        "      ----- INPUT -----\n",
        "      image -> tensor 2*#batch_size x #channels x width x height\n",
        "\n",
        "      ----- OUTPUT -----\n",
        "      tensor -> 2*#batch_size x 1\n",
        "      \"\"\"\n",
        "      self.output = self.net(images)\n",
        "      self.output = self.output.to(torch.float32) #aggiunto questo \n",
        "      return self.output \n",
        "      \n",
        "    def function_loss_D(self,output_label_dis,true_label):\n",
        "      \"\"\"\n",
        "      ----- INPUT -----\n",
        "      output_label_dis -> 2*#batch_size x 1\n",
        "      true_label -> 2*#batch_size x 1 \n",
        "      \n",
        "      ----- OUTPUT -----\n",
        "      loss function\n",
        "\n",
        "      \"\"\"\n",
        "      cost_function = nn.BCELoss()\n",
        "      true_label = true_label.to(torch.float) #aggiunto questo \n",
        "      loss = cost_function(output_label_dis,true_label)\n",
        "\n",
        "      return loss\n",
        "\n",
        "    def save(self,file_name):\n",
        "      torch.save(self.net.state_dict(), file_name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_22igvDX_Deu"
      },
      "source": [
        "# Train functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1PXaV6NG_T_w"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_lr(architecture_G,architecture_D,batch_size,n_epochs,dataset,lr_g,lr_d,processing_unit,p_subset):\n",
        "\n",
        "    \"\"\"\n",
        "    I change the learning rate\n",
        "\n",
        "    ----- INPUT -----\n",
        "    Generator -> class of the generator\n",
        "    Discriminator -> class of the discriminator\n",
        "    batch_size,n_epochs,lr -> number\n",
        "    dataset -> -> object dataset  \n",
        "\n",
        "    ----- OUTPUT -----\n",
        "    metrics to measure the accuracy of the models \n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    gen_net = architecture_G\n",
        "    dis_net = architecture_D\n",
        "    best_epoch_G = -1\n",
        "    best_epoch_D = -1\n",
        "\n",
        "    dataset.preprocessing(p_subset) \n",
        "    \n",
        "    \n",
        "    optimizer_gen = torch.optim.Adam([p for p in gen_net.net.parameters() if p.requires_grad], lr_g, maximize=True) #torch.optim.Adam(filter(lambda p: p.requires_grad, self.net.parameters()), lr)\n",
        "    optimizer_dis = torch.optim.Adam([p for p in dis_net.net.parameters() if p.requires_grad], lr_d, maximize=False)\n",
        "\n",
        "    best_loss_D = 1000000000000 \n",
        "    best_loss_G = 1000000000000\n",
        "\n",
        "    gen_net.net.train()\n",
        "    dis_net.net.train()\n",
        "\n",
        "    loss_G_batch = []\n",
        "    loss_D_batch = []\n",
        "\n",
        "\n",
        "    for e in range(0,n_epochs):\n",
        "\n",
        "\n",
        "        last_batch = False\n",
        "\n",
        "        image_file, _ = dataset.shuffled_dataset()\n",
        "        length_dataset = len(image_file)\n",
        "\n",
        "        counter_batches = 0\n",
        "        avg_loss_D = 0\n",
        "        avg_loss_G = 0\n",
        "\n",
        "        while not last_batch:\n",
        "\n",
        "            counter_batches = counter_batches + 1\n",
        "\n",
        "            #fake batch creation\n",
        "            x_gen_input, _ = gen_net.input_creation(length_dataset = length_dataset , batch_size = batch_size)\n",
        "            current_batch_dim = x_gen_input.shape\n",
        "\n",
        "            with torch.no_grad():\n",
        "                #move the data into the processing unit device\n",
        "                x_gen_input = x_gen_input.to(processing_unit)\n",
        "                #fake image generated by Generator\n",
        "                image_output_fake,label_fake_img = gen_net.forward_G(x_gen_input)\n",
        "\n",
        "            #true image generation\n",
        "            mini_batch_image_real, mini_batch_label_real, last_batch_flag = dataset.mini_batch_creation(batch_size,image_file)\n",
        "\n",
        "            #combination real/fake image into the cpu\n",
        "            image_output_fake = image_output_fake.to('cpu')\n",
        "            label_fake_img = label_fake_img.to('cpu')\n",
        "            mini_batch_img_comb, mini_batch_lab_comb  = dis_net.combined_True_Fake(\n",
        "                fake_labels = label_fake_img, fake_images = image_output_fake, \n",
        "                true_labels = mini_batch_label_real , true_images = mini_batch_image_real\n",
        "            )\n",
        "\n",
        "            #relocate the combined images into the processing unit \n",
        "            mini_batch_img_comb = mini_batch_img_comb.to(processing_unit)\n",
        "            predicted_label = dis_net.forward_D(mini_batch_img_comb)\n",
        "\n",
        "            #------------\n",
        "            # BackProp Discriminator \n",
        "            #------------\n",
        "            \n",
        "            #move to processing unit \n",
        "            predicted_label = predicted_label.to(processing_unit)\n",
        "            mini_batch_lab_comb = mini_batch_lab_comb.to(processing_unit)\n",
        "\n",
        "            loss_dis = dis_net.function_loss_D(output_label_dis = predicted_label,true_label = mini_batch_lab_comb)\n",
        "            loss_D_batch.append(loss_dis.item())\n",
        "\n",
        "            avg_loss_D = avg_loss_D + loss_dis\n",
        "            print(\"loss DISCRIMINATOR,\", loss_dis ,avg_loss_D)\n",
        "\n",
        "            optimizer_dis.zero_grad()\n",
        "            loss_dis.backward()\n",
        "            optimizer_dis.step()\n",
        "\n",
        "\n",
        "            #----------\n",
        "            #BackProp Generator\n",
        "            #----------\n",
        "\n",
        "            x_gen_input,_ = gen_net.input_creation(length_dataset = length_dataset , batch_size = batch_size, current_batch_dim = current_batch_dim)\n",
        "            x_gen_input = x_gen_input.to(processing_unit)\n",
        "\n",
        "            image_output_fake,fake_target = gen_net.forward_G(x_gen_input)\n",
        "\n",
        "            predicted_label_generated = dis_net.forward_D(image_output_fake)\n",
        "            fake_target = fake_target.view(-1,1)\n",
        "\n",
        "            #move to processing unit\n",
        "            predicted_label_generated = predicted_label_generated.to(processing_unit)\n",
        "            fake_target = fake_target.to(processing_unit)\n",
        "\n",
        "            loss_gen = gen_net.function_loss_G(output_label_gen = predicted_label_generated, true_label = fake_target)\n",
        "\n",
        "            loss_G_batch.append(loss_gen.item())\n",
        "            avg_loss_G = avg_loss_G + loss_gen \n",
        "\n",
        "            print(\"loss GENERATOR\", loss_gen, avg_loss_G)\n",
        "\n",
        "            optimizer_gen.zero_grad()\n",
        "            loss_gen.backward()\n",
        "            optimizer_gen.step()\n",
        "            \n",
        "\n",
        "            last_batch = last_batch_flag\n",
        "\n",
        "\n",
        "        #gen_net.image_generation()\n",
        "\n",
        "        avg_loss_G = avg_loss_G/counter_batches\n",
        "        avg_loss_D = avg_loss_D/counter_batches\n",
        "\n",
        "        if avg_loss_D < best_loss_D:\n",
        "            best_loss_D = avg_loss_D\n",
        "            best_epoch_D = e + 1\n",
        "            dis_net.save(\"weights_discriminator.pth\")\n",
        "            \n",
        "        if avg_loss_G < best_loss_G:\n",
        "          best_loss_G = avg_loss_G\n",
        "          best_epoch_G = e + 1\n",
        "          gen_net.save(\"weights_generator.pth\")\n",
        "\n",
        "       \n",
        "        print(\"epoch:{0}/{1}\".format(e+1,n_epochs)) \n",
        "              \n",
        "        print((\"DISCRIMIATOR: BCE LOSS={0:.4f}\"\n",
        "                   + (\", BEST!\" if avg_loss_D == best_loss_D else \"\"))\n",
        "                  .format(avg_loss_D))\n",
        "            \n",
        "        print((\"GENERATOR: BCE LOSS={0:.4f}\"\n",
        "                   + (\", BEST!\" if avg_loss_G == best_loss_G else \"\"))\n",
        "                  .format(avg_loss_G))\n",
        "            \n",
        "        print(\"========================================================================================= \\n\")\n",
        "\n",
        "    plt.plot(loss_G_batch)\n",
        "    plt.plot(loss_D_batch)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def separation(predicted_label):\n",
        "\n",
        "    \"\"\"\n",
        "    divide the true from the generated data in orded to do backprop in the generator \n",
        "    \"\"\"\n",
        "\n",
        "    length = int(predicted_label.shape[0]/2)\n",
        "\n",
        "    fake_label = predicted_label[length:]\n",
        "    fake_label = fake_label.view(1,-1)\n",
        "\n",
        "    return fake_label\n",
        "    \n",
        "\n",
        "\n",
        "def train_lr_obj(Generator,Discriminator,batch_size,n_epochs,dataset,lr_g,lr_d,processing_unit,p_subset):\n",
        "\n",
        "    \"\"\"\n",
        "    Here I modify the learning rate and also the cost function of the generator. Indeed, now I do not want to maximize sum(-(1-y)log(D(G))) but rather\n",
        "    I aim to minizime sum(ylog(D(G))). For this reason i falsly impose y = 1. \n",
        "\n",
        "    ----- INPUT -----\n",
        "    Generator -> class of the generator\n",
        "    Discriminator -> class of the discriminator\n",
        "    batch_size,n_epochs,lr -> number\n",
        "    dataset -> -> object dataset  \n",
        "\n",
        "    ----- OUTPUT -----\n",
        "    metrics to measure the accuracy of the models \n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    gen_net = Generator\n",
        "    dis_net = Discriminator\n",
        "    best_epoch_G = -1\n",
        "    best_epoch_D = -1\n",
        "\n",
        "    dataset.preprocessing(p_subset) \n",
        "    \n",
        "\n",
        "    \n",
        "    optimizer_gen = torch.optim.Adam([p for p in gen_net.net.parameters() if p.requires_grad], lr_g, maximize=False) \n",
        "    optimizer_dis = torch.optim.Adam([p for p in dis_net.net.parameters() if p.requires_grad], lr_d, maximize=False)\n",
        "\n",
        "    best_loss_D = 1000000000000 \n",
        "    best_loss_G = 1000000000000\n",
        "\n",
        "    gen_net.net.train()\n",
        "    dis_net.net.train()\n",
        "\n",
        "    for e in range(0,n_epochs):\n",
        "\n",
        "\n",
        "        last_batch = False\n",
        "\n",
        "        image_file, _ = dataset.shuffled_dataset()\n",
        "        length_dataset = len(image_file)\n",
        "\n",
        "        counter_batches = 0\n",
        "        tot_loss_D = 0\n",
        "        tot_loss_G = 0\n",
        "        avg_loss_D = 0\n",
        "        avg_loss_G = 0\n",
        "\n",
        "        while not last_batch:\n",
        "\n",
        "            counter_batches = counter_batches + 1\n",
        "\n",
        "            #fake batch creation\n",
        "            x_gen_input, _ = gen_net.input_creation(length_dataset = length_dataset , batch_size = batch_size)\n",
        "            current_batch_dim = x_gen_input.shape\n",
        "\n",
        "            with torch.no_grad():\n",
        "                #move the data into the processing unit device\n",
        "                x_gen_input = x_gen_input.to(processing_unit)\n",
        "                #fake image generated by Generator\n",
        "                image_output_fake,label_fake_img = gen_net.forward_G(x_gen_input)\n",
        "\n",
        "            #true image generation\n",
        "            mini_batch_image_real, mini_batch_label_real, last_batch_flag = dataset.mini_batch_creation(batch_size,image_file)\n",
        "\n",
        "            #combination real/fake image into the cpu\n",
        "            image_output_fake = image_output_fake.to('cpu')\n",
        "            label_fake_img = label_fake_img.to('cpu')\n",
        "            mini_batch_img_comb, mini_batch_lab_comb  = dis_net.combined_True_Fake(\n",
        "                fake_labels = label_fake_img, fake_images = image_output_fake, \n",
        "                true_labels = mini_batch_label_real , true_images = mini_batch_image_real\n",
        "            )\n",
        "\n",
        "            #relocate the combined images into the processing unit \n",
        "            mini_batch_img_comb = mini_batch_img_comb.to(processing_unit)\n",
        "            predicted_label = dis_net.forward_D(mini_batch_img_comb)\n",
        "\n",
        "            #------------\n",
        "            # BackProp Discriminator \n",
        "            #------------\n",
        "            \n",
        "            #move to processing unit \n",
        "            predicted_label = predicted_label.to(processing_unit)\n",
        "            mini_batch_lab_comb = mini_batch_lab_comb.to(processing_unit)\n",
        "\n",
        "            loss_dis = dis_net.function_loss_D(output_label_dis = predicted_label,true_label = mini_batch_lab_comb)\n",
        "            tot_loss_D = tot_loss_D + loss_dis\n",
        "\n",
        "            optimizer_dis.zero_grad()\n",
        "            loss_dis.backward()\n",
        "            optimizer_dis.step()\n",
        "\n",
        "\n",
        "            #----------\n",
        "            #BackProp Generator\n",
        "            #----------\n",
        "\n",
        "            x_gen_input,_ = gen_net.input_creation(length_dataset = length_dataset , batch_size = batch_size, current_batch_dim = current_batch_dim)\n",
        "            x_gen_input = x_gen_input.to(processing_unit)\n",
        "\n",
        "            x_gen_input,_ = gen_net.input_creation(length_dataset = length_dataset , batch_size = batch_size, current_batch_dim = current_batch_dim)\n",
        "            image_output_fake,_ = gen_net.forward_G(x_gen_input)\n",
        "            predicted_label_generated = dis_net.forward_D(image_output_fake)\n",
        "\n",
        "            #move to processing unit\n",
        "            predicted_label_generated = predicted_label_generated.to(processing_unit)\n",
        "            mini_batch_label_real = mini_batch_label_real.view(-1,1).to(processing_unit)\n",
        "\n",
        "            loss_gen = gen_net.function_loss_G(output_label_gen=predicted_label_generated, true_label=mini_batch_label_real)    \n",
        "\n",
        "            tot_loss_G = tot_loss_G + loss_gen \n",
        "\n",
        "            optimizer_gen.zero_grad()\n",
        "            loss_gen.backward()\n",
        "            optimizer_gen.step()\n",
        "            \n",
        "\n",
        "            last_batch = last_batch_flag\n",
        "\n",
        "\n",
        "        #gen_net.image_generation()\n",
        "\n",
        "        avg_loss_G = tot_loss_G/counter_batches\n",
        "        avg_loss_D = tot_loss_D/counter_batches\n",
        "\n",
        "        if avg_loss_D < best_loss_D:\n",
        "            best_loss_D = avg_loss_D\n",
        "            best_epoch_D = e + 1\n",
        "            dis_net.save(\"weights_discriminator.pth\")\n",
        "            \n",
        "        if avg_loss_G < best_loss_G:\n",
        "          best_loss_G = avg_loss_G\n",
        "          best_epoch_G = e + 1\n",
        "          gen_net.save(\"weights_generator.pth\")\n",
        "\n",
        "       \n",
        "        print(\"epoch:{0}/{1}\".format(e+1,n_epochs)) \n",
        "              \n",
        "        print((\"DISCRIMIATOR: BCE LOSS={0:.4f}\"\n",
        "                   + (\", BEST!\" if avg_loss_D == best_loss_D else \"\"))\n",
        "                  .format(avg_loss_D))\n",
        "            \n",
        "        print((\"GENERATOR: BCE LOSS={0:.4f}\"\n",
        "                   + (\", BEST!\" if avg_loss_G == best_loss_G else \"\"))\n",
        "                  .format(avg_loss_G))\n",
        "            \n",
        "        print(\"========================================================================================= \\n\")\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yV91YkH8APoi"
      },
      "source": [
        "# main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMoiOcFqAQs9"
      },
      "outputs": [],
      "source": [
        "processing_unit = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "p_subset = 0.25\n",
        "lr_g = 0.001\n",
        "lr_d = 0.00001\n",
        "dataset = Dataset(path_destination=\"/content/img_celeba_dataset\")\n",
        "gen_net = Generator(processing_unit,\"conventional\")\n",
        "dis_net = Discriminator(processing_unit)\n",
        "\n",
        "train_lr(architecture_G=gen_net,architecture_D=dis_net,batch_size=128,n_epochs=10,dataset=dataset,lr_g=0.001,lr_d=0.00001,processing_unit = processing_unit,p_subset=p_subset)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOhHLOvSiAQq09JrXMJ1MDx",
      "collapsed_sections": [
        "UBv2cPtN-Gr6",
        "HWR8ZEEB-yHw"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "NN_proj_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6 (v3.9.6:db3ff76da1, Jun 28 2021, 11:49:53) \n[Clang 6.0 (clang-600.0.57)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "8da97b3eb1026c5cd863651ec7b5e28ca1695a5a9d6bc8af194926f5a1e740b7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
